

import axios from "axios";
import OpenAI from "openai";
import { Readable } from "stream";

import getOptimizedAmandaResponse from "../utils/amandaOrchestrator.js";
import { CLINIC_ADDRESS, SYSTEM_PROMPT_AMANDA } from "../utils/amandaPrompt.js";

// ‚ö†Ô∏è novos imports para m√≠dia baseada em mediaId
import ensureSingleHeart from "../utils/helpers.js";
import callAI from "./IA/Aiproviderservice.js";
import { analyzeLeadMessage } from "./intelligence/leadIntelligence.js";
import { getMediaBuffer } from "./whatsappMediaService.js";

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

/* =========================================================================
   üéØ RESPOSTA PRINCIPAL - USA ORCHESTRATOR (MANTIDO)
   ========================================================================= */

export async function generateAmandaReply({ userText, lead = {}, context = {} }) {

    try {
        return await getOptimizedAmandaResponse({
            content: userText,
            userText,
            lead,
            context,
        });

    } catch (err) {

        console.warn("‚ö†Ô∏è Orchestrator falhou, usando OpenAI FREE");

        try {
            const fallback = await callOpenAIFallback({
                systemPrompt: SYSTEM_PROMPT_AMANDA,
                messages: [
                    { role: "user", content: userText }
                ]
            });

            if (fallback) return fallback;

        } catch (e) {
            console.error("‚ùå Fallback OpenAI falhou:", e.message);
        }

        return "Tive um probleminha t√©cnico üòï J√° te ajudo üíö";
    }
}

/* =========================================================================
   üìû FOLLOW-UP (AGORA USANDO leadIntelligence + CEN√ÅRIOS)
   ========================================================================= */
export async function generateFollowupMessage(lead) {
    const name = lead?.name?.split(" ")[0] || "tudo bem";
    const reason = (lead?.reason || "avalia√ß√£o/terapia").trim();
    const origin = lead?.origin || "WhatsApp";

    // üîé Pega a √∫ltima intera√ß√£o registrada no lead
    const lastInteraction = Array.isArray(lead?.interactions) && lead.interactions.length > 0
        ? lead.interactions[lead.interactions.length - 1]
        : null;

    const lastMsg = (lastInteraction?.message || "").trim();
    const lastMsgDesc = lastMsg || reason || "h√° alguns dias voc√™s conversaram sobre avalia√ß√£o/terapia";

    // ‚è±Ô∏è dias desde a √∫ltima intera√ß√£o (se o modelo de lead tiver isso)
    const lastAt = lead.lastInteractionAt ? new Date(lead.lastInteractionAt).getTime() : null;
    const now = Date.now();
    const daysSinceLast = lastAt ? Math.round((now - lastAt) / (1000 * 60 * 60 * 24)) : null;

    // üß† Analisa inten√ß√£o, urg√™ncia, score etc. usando o teu leadIntelligence
    let analysis = null;
    try {
        analysis = await analyzeLeadMessage({
            text: lastMsgDesc,
            lead,
            history: Array.isArray(lead.interactions) ? lead.interactions : [],
        });
    } catch (err) {
        console.error("‚ö†Ô∏è Erro em analyzeLeadMessage no follow-up:", err.message);
    }

    const extracted = analysis?.extracted || {};
    const intent = analysis?.intent || {};
    const stage = lead.stage || 'novo';

    const segment = analysis?.segment || {
        label: lead.conversionScore >= 80 ? "hot" : lead.conversionScore >= 50 ? "warm" : "cold",
        emoji: lead.conversionScore >= 80 ? "üî•" : lead.conversionScore >= 50 ? "üü°" : "üßä",
    };

    // üß© Sinais de contexto espec√≠ficos da √öLTIMA fala
    const talksAboutPrice =
        /(pre[√ßc]o|valor|valores|custa|mensalidade|pacote|tabela|or√ßamento|orcamento)/i.test(lastMsgDesc);

    const talksAboutThinking =
        /(vou\s+ver|vou\s+avaliar|vou\s+pensar|vou\s+conversar\s+com|depois\s+te\s+dou\s+retorno)/i
            .test(lastMsgDesc);

    const saidWillTalkToSpouseOrFamily =
        /(vou\s+(falar|conversar)\s+com\s+(meu\s+marido|minha\s+esposa|minha\s+mulher|meu\s+esposo|minha\s+companheira|meu\s+companheiro|minha\s+m[a√£]e|meu\s+pai|meus\s+pais|fam[i√≠]lia))/i
            .test(lastMsgDesc);

    const saidWillCheckPlan =
        /\b(vou\s+ver|vou\s+checar|vou\s+olhar)\b.*\b(plano|conv[e√™]nio|unimed|ipasgo|amil)\b/i
            .test(lastMsgDesc);

    const saidWillCheckSchedule =
        /\b(vou\s+ver|vou\s+olhar|vou\s+organizar)\b.*\b(agenda|hor[a√°]rio|rotina)\b/i
            .test(lastMsgDesc);

    const askedForHuman =
        /(falar\s+com\s+atendente|falar\s+com\s+uma\s+pessoa|secret[a√°]ria|atendente)/i.test(lastMsgDesc);

    // üîô Se a √∫ltima mensagem foi pedindo atendente humana, √© mais seguro N√ÉO mandar follow-up autom√°tico
    if (askedForHuman) {
        console.log("[Followup] √öltima mensagem pediu atendente humana ‚Äî n√£o envia follow-up autom√°tico.");
        return null;
    }

    // üéØ Template-base s√≥ como "clima" / fallback
    const baseTemplateValores = `Oi, ${name}! üòä
    S√≥ passei para ver se conseguiu analisar os valores e se posso te ajudar com algo mais üíö

    Se quiser, j√° te envio os hor√°rios dispon√≠veis para a avalia√ß√£o ‚ú®`;

    const baseTemplateGeral = `Oi, ${name}! üòä
    S√≥ passei para saber se conseguiu ver com calma as informa√ß√µes que combinamos e se posso te ajudar com algo a mais üíö

    Se quiser, j√° te envio os hor√°rios dispon√≠veis para a avalia√ß√£o ‚ú®`;

    const baseTemplate = talksAboutPrice || talksAboutThinking ? baseTemplateValores : baseTemplateGeral;

    // üß† Monta descri√ß√£o de cen√°rio pra IA enxergar o contexto
    const scenarioNotes = [];

    scenarioNotes.push(`- Segmento atual: ${segment.label.toUpperCase()} ${segment.emoji}`);
    scenarioNotes.push(`- Inten√ß√£o prim√°ria detectada: ${intent.primary || "duvida_geral"}`);
    scenarioNotes.push(`- Urg√™ncia detectada: ${extracted.urgencia || "normal"}`);

    if (daysSinceLast != null) {
        scenarioNotes.push(`- Dias sem resposta: ${daysSinceLast} dia(s)`);
    }

    if (talksAboutPrice) {
        scenarioNotes.push("- O lead falou de valores/pre√ßo na √∫ltima conversa.");
    }
    if (talksAboutThinking) {
        scenarioNotes.push("- O lead disse que iria pensar/ver melhor antes de decidir.");
    }
    if (saidWillTalkToSpouseOrFamily) {
        scenarioNotes.push("- O lead disse que iria conversar com marido/esposa/fam√≠lia.");
    }
    if (saidWillCheckPlan) {
        scenarioNotes.push("- O lead disse que iria ver quest√£o de plano/conv√™nio.");
    }
    if (saidWillCheckSchedule) {
        scenarioNotes.push("- O lead disse que iria ver agenda/hor√°rio/rotina.");
    }

    const scenarioBlock = scenarioNotes.join("\n");

    // üßæ Prompt COMPLETO que guia o Claude, agora com CEN√ÅRIO expl√≠cito
    const userPrompt = `
    Quero que voc√™ gere UMA mensagem curta de follow-up para um lead da Cl√≠nica Fono Inova.

    DADOS DO LEAD:
    - Nome: ${name}
    - Origem: ${origin}
    - Motivo/raz√£o: ${reason}
    - √öltima intera√ß√£o relevante: "${lastMsgDesc}"
    - Est√°gio atual do lead no funil: ${stage}

    CEN√ÅRIO ANALISADO (via intelig√™ncia interna):
    ${scenarioBlock || "- Cen√°rio geral de retomada ap√≥s envio de informa√ß√µes."}

    INTERPRETA√á√ÉO DO CEN√ÅRIO:
    - Se o lead falou que iria conversar com marido/esposa/fam√≠lia, a mensagem deve relembrar isso de forma acolhedora (ex.: "voc√™s chegaram a conversar sobre isso?").
    - Se o lead falou que iria ver valores/contas, a mensagem deve reconhecer isso com leveza (sem pressionar) e refor√ßar o valor da avalia√ß√£o/visita.
    - Se o lead falou que iria ver plano/conv√™nio, a mensagem pode refor√ßar que muitas fam√≠lias usam plano, mas buscam o particular para come√ßar mais r√°pido.
    - Se o lead falou que iria ver agenda/rotina, acolha a correria e mostre que d√° para come√ßar de forma leve.
    - Se o segmento for HOT (üî•), voc√™ pode ser um pouco mais direto ao oferecer ajuda para escolher dia/turno.
    - Se o segmento for COLD (üßä), a mensagem deve ser bem leve, mais lembrando que estamos √† disposi√ß√£o do que cobrando decis√£o.

    ESTILO BASE (N√ÉO COPIAR IGUAL, S√ì O CLIMA):
    "${baseTemplate}"

    REGRAS DE ESTILO:
    - 2 a 3 frases no m√°ximo.
    - Tom leve, humano, nada rob√≥tico.
    - Tratar o lead pelo primeiro nome.
    - Se houver contexto de valores, mencionar de forma suave que est√° vendo se conseguiu analisar os valores.
    - Em todos os casos, oferecer ajuda + possibilidade de enviar hor√°rios dispon√≠veis para avalia√ß√£o ou visita.
    - Sempre terminar com uma pergunta de ESCOLHA BIN√ÅRIA (por exemplo: "ficou melhor essa semana ou prefere deixar para a pr√≥xima?", "prefere primeiro ver hor√°rios ou tirar mais uma d√∫vida?").
    - Exatamente 1 üíö na mensagem inteira.
    - Pode usar 1 ou 2 emojis leves (üòä, ‚ú®), sem exagero.
    - N√ÉO insista demais: √© um lembrete educado, n√£o cobran√ßa.

    DADOS NUM√âRICOS:
    - Score atual: ${lead.conversionScore ?? "sem score"}/100
    - N√≠vel de urg√™ncia interna: ${lead.qualificationData?.urgencyLevel || 2}/3
    - Segmento (interno): ${segment.label.toUpperCase()} ${segment.emoji}

    Gere APENAS o texto da mensagem pronta para ser enviada no WhatsApp, em portugu√™s do Brasil.`.trim();

    try {
        const text = await callAI({
            systemPrompt: SYSTEM_PROMPT_AMANDA,
            messages: [{ role: "user", content: userPrompt }],
            maxTokens: 220,
            temperature: 0.7
        });

        // Se por algum motivo vier vazio, usa o template base
        const final = text || baseTemplate;
        return ensureSingleHeart(final); // garante s√≥ 1 üíö
    } catch (error) {
        console.error("‚ùå Erro ao gerar follow-up:", error);
        // fallback se Claude der pau
        return ensureSingleHeart(baseTemplate);
    }
}


/* =========================================================================
   üéôÔ∏è TRANSCRI√á√ÉO DE √ÅUDIO - VERS√ÉO NOVA (mediaId ‚Üí buffer ‚Üí Whisper)
   ========================================================================= */
export async function transcribeWaAudio(mediaId, fileName = "audio.ogg") {
    console.log(`üéôÔ∏è Iniciando transcri√ß√£o: ${mediaId}`);

    try {
        // 1Ô∏è‚É£ Baixa o √°udio via Graph (service unificado)
        const { buffer, mimeType } = await getMediaBuffer(mediaId);

        console.log(`üìä √Åudio: ${buffer.length} bytes, tipo: ${mimeType}`);

        const stream = Readable.from(buffer);
        stream.path = fileName;

        const resp = await openai.audio.transcriptions.create({
            file: stream,
            model: "whisper-1",
            language: "pt",
            temperature: 0.2,
        });

        return (resp?.text || "").trim();
    } catch (error) {
        console.error("‚ùå Erro na transcri√ß√£o (transcribeWaAudio):", error.message);
        return "";
    }
}

/* =========================================================================
   üéôÔ∏è TRANSCRI√á√ÉO DE √ÅUDIO - VERS√ÉO ANTIGA (URL direta)
   ‚Üí Mantida por compatibilidade, se ainda houver c√≥digo chamando
   ========================================================================= */
export async function transcribeWaAudioFromGraph({
    mediaUrl,
    fileName = "audio.ogg",
} = {}) {
    try {
        const { data } = await axios.get(mediaUrl, {
            responseType: "arraybuffer",
            timeout: 20000,
        });

        const buffer = Buffer.from(data);
        const stream = Readable.from(buffer);
        stream.path = fileName;

        const resp = await openai.audio.transcriptions.create({
            file: stream,
            model: "whisper-1",
            language: "pt",
            temperature: 0.2,
        });

        return (resp?.text || "").trim();
    } catch (error) {
        console.error("‚ùå Erro ao transcrever √°udio (FromGraph):", error.message);
        return "";
    }
}

// =====================================================================
// üîÑ FALLBACK OPENAI (quando Anthropic falha)
// =====================================================================
export async function callOpenAIFallback({ systemPrompt, messages, maxTokens = 200, temperature = 0.7 }) {
    const openaiMessages = [
        { role: "system", content: systemPrompt },
        ...messages.map(msg => ({
            role: msg.role,
            content: typeof msg.content === 'string'
                ? msg.content
                : JSON.stringify(msg.content)
        }))
    ];

    const response = await openai.chat.completions.create({
        model: "gpt-4o-mini",
        messages: openaiMessages,
        max_tokens: maxTokens,
        temperature
    });

    return response.choices[0]?.message?.content?.trim() || null;
}
/* =========================================================================
   üñºÔ∏è DESCRI√á√ÉO DE IMAGEM - NOVA (mediaId ‚Üí buffer ‚Üí dataURL ‚Üí GPT-4o-mini)
   ========================================================================= */
export async function describeWaImage(mediaId, caption = "") {
    console.log(`üñºÔ∏è Processando imagem: ${mediaId}`);

    try {
        // 1Ô∏è‚É£ Baixa o bin√°rio da m√≠dia (como j√° faz com √°udio)
        const { buffer, mimeType } = await getMediaBuffer(mediaId);

        console.log(`üñºÔ∏è Imagem carregada: ${buffer.length} bytes, tipo: ${mimeType}`);

        // 2Ô∏è‚É£ Converte para data URL (base64)
        const base64 = buffer.toString("base64");
        const dataUrl = `data:${mimeType || "image/jpeg"};base64,${base64}`;

        // 3Ô∏è‚É£ Envia para o GPT-4o-mini usando image_url com data URL
        const resp = await openai.chat.completions.create({
            model: "gpt-4o-mini",
            temperature: 0.4,
            max_tokens: 120,
            messages: [
                {
                    role: "system",
                    content:
                        "Voc√™ √© a Amanda da Cl√≠nica Fono Inova. Descreva brevemente a imagem em 1-2 frases, em pt-BR.",
                },
                {
                    role: "user",
                    content: [
                        {
                            type: "text",
                            text: `Legenda: ${caption || "(sem legenda)"}`,
                        },
                        {
                            type: "image_url",
                            image_url: { url: dataUrl },
                        },
                    ],
                },
            ],
        });

        return (resp.choices?.[0]?.message?.content || "").trim();
    } catch (error) {
        console.error("‚ùå Erro ao descrever imagem (describeWaImage):", error.message);
        return "";
    }
}


/* =========================================================================
   üñºÔ∏è DESCRI√á√ÉO DE IMAGEM - ANTIGA (URL direta)
   ‚Üí Mantida por compatibilidade
   ========================================================================= */
export async function describeWaImageFromGraph({ imageUrl, caption = "" } = {}) {
    try {
        const resp = await openai.chat.completions.create({
            model: "gpt-4o-mini",
            temperature: 0.4,
            max_tokens: 120,
            messages: [
                {
                    role: "system",
                    content:
                        "Voc√™ √© a Amanda da Cl√≠nica Fono Inova. Descreva brevemente a imagem em 1-2 frases, em pt-BR.",
                },
                {
                    role: "user",
                    content: [
                        { type: "text", text: `Legenda: ${caption || "(sem legenda)"}` },
                        { type: "image_url", image_url: { url: imageUrl } },
                    ],
                },
            ],
        });

        return (resp.choices?.[0]?.message?.content || "").trim();
    } catch (error) {
        console.error(
            "‚ùå Erro ao descrever imagem (FromGraph):",
            error.message
        );
        return "";
    }
}

// Exporta CLINIC_ADDRESS e SYSTEM_PROMPT_AMANDA para compatibilidade
export { CLINIC_ADDRESS, SYSTEM_PROMPT_AMANDA };
