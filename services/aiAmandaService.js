// services/aiAmandaService.js - VERS√ÉO UNIFICADA (Amanda 1.0 + m√≠dia nova)
import Anthropic from "@anthropic-ai/sdk";
import axios from "axios";
import OpenAI from "openai";
import { Readable } from "stream";

import getOptimizedAmandaResponse from "../utils/amandaOrchestrator.js";
import { CLINIC_ADDRESS, SYSTEM_PROMPT_AMANDA } from "../utils/amandaPrompt.js";

// ‚ö†Ô∏è novos imports para m√≠dia baseada em mediaId
import { getMediaBuffer } from "./whatsappMediaService.js";

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
const anthropic = new Anthropic({ apiKey: process.env.ANTHROPIC_API_KEY });

/* =========================================================================
   üéØ RESPOSTA PRINCIPAL - USA ORCHESTRATOR (MANTIDO)
   ========================================================================= */
export async function generateAmandaReply({ userText, lead = {}, context = {} }) {
    try {
        const response = await getOptimizedAmandaResponse({
            content: userText,
            userText,
            lead,
            context,
        });

        console.log("[AmandaReply] Resposta gerada:", response);
        return response;
    } catch (error) {
        console.error("‚ùå Erro em generateAmandaReply:", error);
        return "Vou verificar e j√° te retorno, por favor um momento üíö";
    }
}

/* =========================================================================
   üìû FOLLOW-UP (MANTIDO COM CLAUDE + üíö √öNICO)
   ========================================================================= */
export async function generateFollowupMessage(lead) {
    const name = lead?.name?.split(" ")[0] || "tudo bem";
    const reason = lead?.reason || "avalia√ß√£o/terapia";
    const origin = lead?.origin || "WhatsApp";

    // üîé Pega a √∫ltima intera√ß√£o registrada no lead
    const lastInteraction = Array.isArray(lead?.interactions) && lead.interactions.length > 0
        ? lead.interactions[lead.interactions.length - 1]
        : null;

    const lastMsg = (lastInteraction?.message || "").trim();

    // üß† Sinais de contexto para o follow-up
    const talksAboutPrice =
        /(pre[√ßc]o|valor|valores|custa|mensalidade|pacote|tabela|or√ßamento|orcamento)/i.test(lastMsg) ||
        /(pre[√ßc]o|valor|valores|custa|mensalidade|pacote|tabela|or√ßamento|orcamento)/i.test(reason);

    const talksAboutThinking =
        /(vou\s+ver|vou\s+avaliar|vou\s+pensar|vou\s+conversar\s+com|depois\s+te\s+dou\s+retorno|ver\s+com\s+meu\s+espos[oa])/i
            .test(lastMsg);

    const askedForHuman =
        /(falar\s+com\s+atendente|falar\s+com\s+uma\s+pessoa|secret[a√°]ria|atendente)/i.test(lastMsg);

    // üéØ Template-base que voc√™ quer pra PRIMEIRO follow-up ‚Äúpadr√£o valores‚Äù
    const baseTemplateValores = `Oi, ${name}! üòä
S√≥ passei para ver se conseguiu analisar os valores e se posso te ajudar com algo mais üíö

Se quiser, j√° te envio os hor√°rios dispon√≠veis para a avalia√ß√£o ‚ú®`;

    // Vers√£o mais gen√©rica (quando n√£o t√° claramente falando de pre√ßo)
    const baseTemplateGeral = `Oi, ${name}! üòä
S√≥ passei para saber se conseguiu ver com calma as informa√ß√µes que combinamos e se posso te ajudar com algo a mais üíö

Se quiser, j√° te envio os hor√°rios dispon√≠veis para a avalia√ß√£o ‚ú®`;

    // Decide qual template usar como ‚Äú√¢ncora‚Äù
    const baseTemplate = talksAboutPrice || talksAboutThinking ? baseTemplateValores : baseTemplateGeral;

    const lastMsgDesc = lastMsg || "h√° alguns dias voc√™s conversaram sobre avalia√ß√£o/terapia";

    // üßæ Prompt COMPLETO que guia o Claude MAS mantendo o CLIMA do teu template
    const userPrompt = `
    Quero que voc√™ gere uma mensagem curta de follow-up para um lead da Cl√≠nica Fono Inova.

    DADOS DO LEAD:
    - Nome: ${name}
    - Origem: ${origin}
    - Motivo/raz√£o: ${reason}
    - √öltima intera√ß√£o relevante: "${lastMsgDesc}"

    CEN√ÅRIO:
    - Essa √© a PRIMEIRA mensagem de follow-up depois de uma conversa onde a pessoa pediu informa√ß√µes,
    falou de valores ou disse que iria pensar/conversar com algu√©m antes de decidir.

    ESTILO BASE (N√ÉO COPIAR IGUAL, MAS MANTER O CLIMA):
    "${baseTemplate}"

    REGRAS:
    - 2 a 3 frases no m√°ximo.
    - Tom leve, humano, nada rob√≥tico.
    - Tratar o lead pelo primeiro nome.
    - Se houver contexto de valores, mencionar de forma suave que est√° vendo se conseguiu analisar os valores.
    - Em todos os casos, oferecer ajuda + possibilidade de enviar hor√°rios dispon√≠veis para avalia√ß√£o.
    - Exatamente 1 üíö na mensagem inteira.
    - Pode usar 1 ou 2 emojis leves (üòä, ‚ú®), sem exagero.
    - N√ÉO insista demais, √© um lembrete educado, n√£o cobran√ßa.

    CONTEXTO ADICIONAL:
    - Score atual: ${lead.conversionScore}/100
    - Urg√™ncia: ${lead.qualificationData?.urgencyLevel || 2}/3
    - Segmento: ${lead.conversionScore >= 80 ? 'üî• HOT' : 'üü° WARM'}

    AJUSTE O TOM:
    - Se score > 70: tom mais direto, ofere√ßa hor√°rios
    - Se score < 50: reforce valor antes de hor√°rios
    `.trim();

    try {
        const resp = await anthropic.messages.create({
            model: "claude-sonnet-4-20250514",
            max_tokens: 200,
            temperature: 0.7,
            system: SYSTEM_PROMPT_AMANDA,
            messages: [
                {
                    role: "user",
                    content: userPrompt,   // üëâ agora usa o prompt completo
                },
            ],
        });

        const text = (resp.content?.[0]?.text || "").trim();

        // Se por algum motivo vier vazio, usa o template que voc√™ ama
        const final = text || baseTemplate;
        return ensureSingleHeart(final); // garante s√≥ 1 üíö
    } catch (error) {
        console.error("‚ùå Erro ao gerar follow-up:", error);
        // fallback se Claude der pau
        return ensureSingleHeart(baseTemplate);
    }
}


/* =========================================================================
   üéôÔ∏è TRANSCRI√á√ÉO DE √ÅUDIO - VERS√ÉO NOVA (mediaId ‚Üí buffer ‚Üí Whisper)
   ========================================================================= */
export async function transcribeWaAudio(mediaId, fileName = "audio.ogg") {
    console.log(`üéôÔ∏è Iniciando transcri√ß√£o: ${mediaId}`);

    try {
        // 1Ô∏è‚É£ Baixa o √°udio via Graph (service unificado)
        const { buffer, mimeType } = await getMediaBuffer(mediaId);

        console.log(`üìä √Åudio: ${buffer.length} bytes, tipo: ${mimeType}`);

        const stream = Readable.from(buffer);
        stream.path = fileName;

        const resp = await openai.audio.transcriptions.create({
            file: stream,
            model: "whisper-1",
            language: "pt",
            temperature: 0.2,
        });

        return (resp?.text || "").trim();
    } catch (error) {
        console.error("‚ùå Erro na transcri√ß√£o (transcribeWaAudio):", error.message);
        return "";
    }
}

/* =========================================================================
   üéôÔ∏è TRANSCRI√á√ÉO DE √ÅUDIO - VERS√ÉO ANTIGA (URL direta)
   ‚Üí Mantida por compatibilidade, se ainda houver c√≥digo chamando
   ========================================================================= */
export async function transcribeWaAudioFromGraph({
    mediaUrl,
    fileName = "audio.ogg",
} = {}) {
    try {
        const { data } = await axios.get(mediaUrl, {
            responseType: "arraybuffer",
            timeout: 20000,
        });

        const buffer = Buffer.from(data);
        const stream = Readable.from(buffer);
        stream.path = fileName;

        const resp = await openai.audio.transcriptions.create({
            file: stream,
            model: "whisper-1",
            language: "pt",
            temperature: 0.2,
        });

        return (resp?.text || "").trim();
    } catch (error) {
        console.error("‚ùå Erro ao transcrever √°udio (FromGraph):", error.message);
        return "";
    }
}

/* =========================================================================
   üñºÔ∏è DESCRI√á√ÉO DE IMAGEM - NOVA (mediaId ‚Üí buffer ‚Üí dataURL ‚Üí GPT-4o-mini)
   ========================================================================= */
export async function describeWaImage(mediaId, caption = "") {
    console.log(`üñºÔ∏è Processando imagem: ${mediaId}`);

    try {
        // 1Ô∏è‚É£ Baixa o bin√°rio da m√≠dia (como j√° faz com √°udio)
        const { buffer, mimeType } = await getMediaBuffer(mediaId);

        console.log(`üñºÔ∏è Imagem carregada: ${buffer.length} bytes, tipo: ${mimeType}`);

        // 2Ô∏è‚É£ Converte para data URL (base64)
        const base64 = buffer.toString("base64");
        const dataUrl = `data:${mimeType || "image/jpeg"};base64,${base64}`;

        // 3Ô∏è‚É£ Envia para o GPT-4o-mini usando image_url com data URL
        const resp = await openai.chat.completions.create({
            model: "gpt-4o-mini",
            temperature: 0.4,
            max_tokens: 120,
            messages: [
                {
                    role: "system",
                    content:
                        "Voc√™ √© a Amanda da Cl√≠nica Fono Inova. Descreva brevemente a imagem em 1-2 frases, em pt-BR.",
                },
                {
                    role: "user",
                    content: [
                        {
                            type: "text",
                            text: `Legenda: ${caption || "(sem legenda)"}`,
                        },
                        {
                            type: "image_url",
                            image_url: { url: dataUrl },
                        },
                    ],
                },
            ],
        });

        return (resp.choices?.[0]?.message?.content || "").trim();
    } catch (error) {
        console.error("‚ùå Erro ao descrever imagem (describeWaImage):", error.message);
        return "";
    }
}


/* =========================================================================
   üñºÔ∏è DESCRI√á√ÉO DE IMAGEM - ANTIGA (URL direta)
   ‚Üí Mantida por compatibilidade
   ========================================================================= */
export async function describeWaImageFromGraph({ imageUrl, caption = "" } = {}) {
    try {
        const resp = await openai.chat.completions.create({
            model: "gpt-4o-mini",
            temperature: 0.4,
            max_tokens: 120,
            messages: [
                {
                    role: "system",
                    content:
                        "Voc√™ √© a Amanda da Cl√≠nica Fono Inova. Descreva brevemente a imagem em 1-2 frases, em pt-BR.",
                },
                {
                    role: "user",
                    content: [
                        { type: "text", text: `Legenda: ${caption || "(sem legenda)"}` },
                        { type: "image_url", image_url: { url: imageUrl } },
                    ],
                },
            ],
        });

        return (resp.choices?.[0]?.message?.content || "").trim();
    } catch (error) {
        console.error(
            "‚ùå Erro ao descrever imagem (FromGraph):",
            error.message
        );
        return "";
    }
}

/* =========================================================================
   üõ†Ô∏è HELPERS
   ========================================================================= */
function ensureSingleHeart(text) {
    if (!text) return "Como posso te ajudar? üíö";
    const clean = text.replace(/üíö/g, "").trim();
    return `${clean} üíö`;
}

// Exporta CLINIC_ADDRESS e SYSTEM_PROMPT_AMANDA para compatibilidade
export { CLINIC_ADDRESS, SYSTEM_PROMPT_AMANDA };
